{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitxyt/stock/blob/main/stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 【1】安装库和检测环境\n",
        "\n",
        "try:\n",
        "    import google.auth\n",
        "    import gspread\n",
        "    import pandas\n",
        "    import requests\n",
        "    import openpyxl\n",
        "    import pytz\n",
        "    from googleapiclient.discovery import build\n",
        "    from gspread_formatting import *\n",
        "except ImportError:\n",
        "    !pip install google-auth gspread gspread-formatting google-api-python-client pandas requests openpyxl pytz"
      ],
      "metadata": {
        "id": "TnH7PbNdSw0F"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 检测是否在Google Colab环境中运行\n",
        "try:\n",
        "    from google.colab import drive, auth  # 用于在Google Colab中挂载Google Drive和进行用户认证\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    # 在Google Colab中运行的设置\n",
        "    drive.mount('/content/drive') # 挂载Google Drive\n",
        "    auth.authenticate_user() # 认证和授权\n",
        "    from google.auth import default\n",
        "    creds, _ = default()\n",
        "else:\n",
        "    # 在本地运行的设置，使用服务账号凭证文件\n",
        "    from google.oauth2.service_account import Credentials\n",
        "    creds = Credentials.from_service_account_file('path/to/your/service_account.json')  # 请替换为你的服务账号文件路径\n",
        "\n",
        "# 使用凭证登录\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "48gyDhnURRTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 【2】数据获取\n",
        "\n",
        "# 2.1 输入参数\n",
        "\n",
        "# 获取当前日期，并将其格式化为\"YYYY-MM-DD\"的字符串\n",
        "today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# 设置股票代码和API Key\n",
        "stock_code = \"AAPL\"\n",
        "api_key = \"VAVS6TS3HVTPGWQ9\"\n",
        "\n"
      ],
      "metadata": {
        "id": "6ZN8SAP1UVjH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 从API获取股票数据并转换为Pandas DataFrame，存放在 original_data 表中\n",
        "\n",
        "# 获取股票数据的函数\n",
        "def get_stock_data(stock_code, api_key):\n",
        "    base_url = \"https://www.alphavantage.co/query\"\n",
        "    params = {\n",
        "        \"function\": \"TIME_SERIES_WEEKLY\",\n",
        "        \"symbol\": stock_code,\n",
        "        \"apikey\": api_key\n",
        "    }\n",
        "    response = requests.get(base_url, params=params)\n",
        "    data = response.json()\n",
        "    return data\n",
        "\n",
        "# 获取股票数据\n",
        "stock_data = get_stock_data(stock_code, api_key)\n",
        "\n",
        "# 将数据转换为Pandas DataFrame\n",
        "time_series = stock_data.get(\"Weekly Time Series\", {})\n",
        "data = {\n",
        "    \"Date\": [],\n",
        "    \"Close\": [],\n",
        "    \"Volume\": []\n",
        "}\n",
        "\n",
        "for date, metrics in time_series.items():\n",
        "    data[\"Date\"].append(date)\n",
        "    data[\"Close\"].append(metrics[\"4. close\"])\n",
        "    data[\"Volume\"].append(metrics[\"5. volume\"])\n",
        "\n",
        "original_data = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "MnUb4-lo0jp7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 【3】处理数据\n",
        "\n",
        "# 3.1 只获取截止到一周收盘的数据\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "\n",
        "\n",
        "# 将 Date 列转换为 datetime 类型\n",
        "original_data['Date'] = pd.to_datetime(original_data['Date'])\n",
        "\n",
        "# 将 Volume 列转换为数值类型\n",
        "original_data['Volume'] = pd.to_numeric(original_data['Volume'], errors='coerce')\n",
        "\n",
        "\n",
        "# 获取当前时间并指定时区，例如使用美国东部时间（ET）\n",
        "now = datetime.now(pytz.timezone('US/Eastern'))\n",
        "\n",
        "# 判断今天是星期几\n",
        "weekday = now.weekday()\n",
        "\n",
        "# 判断是否已经过了周五的市场收盘时间（下午4点）\n",
        "friday_close_time = now.replace(hour=17, minute=0, second=0, microsecond=0)\n",
        "\n",
        "# 如果今天是周六(5)或周日(6)或者是周五且已经过了收盘时间\n",
        "if weekday > 5 or (weekday == 5 and now > friday_close_time):\n",
        "    # 获取本周日的日期\n",
        "    end_date = now + timedelta(days=(6 - weekday))\n",
        "else:\n",
        "    # 获取上周日的日期\n",
        "    end_date = now - timedelta(days=(weekday + 1))\n",
        "\n",
        "# 将 end_date 转换为不含时区信息的 datetime 对象\n",
        "end_date = end_date.replace(tzinfo=None)\n",
        "\n",
        "# 过滤只保留一周收盘后的数据\n",
        "original_data = original_data[original_data['Date'] <= end_date].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "A5oiC4-4WCks"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 【3】数据分析\n",
        "\n",
        "# 3.1 只获取截止到一周收盘的数据\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# 将 Date 列转换为 datetime 类型\n",
        "original_data['Date'] = pd.to_datetime(original_data['Date'])\n",
        "\n",
        "# 将 Volume 列转换为数值类型\n",
        "original_data['Volume'] = pd.to_numeric(original_data['Volume'], errors='coerce')\n",
        "\n",
        "\n",
        "# 获取当前时间并指定时区，例如使用美国东部时间（ET）\n",
        "now = datetime.now(pytz.timezone('US/Eastern'))\n",
        "\n",
        "# 判断今天是星期几\n",
        "weekday = now.weekday()\n",
        "\n",
        "# 判断是否已经过了周五的市场收盘时间（下午4点）\n",
        "friday_close_time = now.replace(hour=17, minute=0, second=0, microsecond=0)\n",
        "\n",
        "# 如果今天是周六(5)或周日(6)或者是周五且已经过了收盘时间\n",
        "if weekday > 5 or (weekday == 5 and now > friday_close_time):\n",
        "    # 获取本周日的日期\n",
        "    end_date = now + timedelta(days=(6 - weekday))\n",
        "else:\n",
        "    # 获取上周日的日期\n",
        "    end_date = now - timedelta(days=(weekday + 1))\n",
        "\n",
        "# 将 end_date 转换为不含时区信息的 datetime 对象\n",
        "end_date = end_date.replace(tzinfo=None)\n",
        "\n",
        "# 过滤只保留一周收盘后的数据\n",
        "original_data = original_data[original_data['Date'] <= end_date].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "0MXS02xQ0w7a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2 添加 Close_Change 列，表示本周收盘价比上周高了还是低了\n",
        "\n",
        "original_data['Close_Change'] = 'NA'  # 默认值\n",
        "for i in range(len(original_data) - 1):\n",
        "    if original_data.loc[i, 'Close'] > original_data.loc[i + 1, 'Close']:\n",
        "        original_data.loc[i, 'Close_Change'] = 'Up'\n",
        "    elif original_data.loc[i, 'Close'] < original_data.loc[i + 1, 'Close']:\n",
        "        original_data.loc[i, 'Close_Change'] = 'Down'"
      ],
      "metadata": {
        "id": "i8C5xRqLMA2Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.3 添加 HighOrLow 列，表示这个价格是不是一个高点/低点\n",
        "\n",
        "original_data['HighOrLow'] = 'NA'  # 默认值\n",
        "\n",
        "# 特殊处理第一行\n",
        "if original_data.loc[0, 'Close_Change'] == 'Up':\n",
        "    original_data.loc[0, 'HighOrLow'] = 'High'\n",
        "elif original_data.loc[0, 'Close_Change'] == 'Down':\n",
        "    original_data.loc[0, 'HighOrLow'] = 'Low'\n",
        "\n",
        "# 处理其他行\n",
        "for i in range(1, len(original_data) - 1):\n",
        "    current_close = original_data.loc[i, 'Close']\n",
        "    previous_close = original_data.loc[i - 1, 'Close']\n",
        "    next_close = original_data.loc[i + 1, 'Close']\n",
        "\n",
        "    if current_close > previous_close and current_close > next_close:\n",
        "        original_data.loc[i, 'HighOrLow'] = 'High'\n",
        "    elif current_close < previous_close and current_close < next_close:\n",
        "        original_data.loc[i, 'HighOrLow'] = 'Low'\n",
        "    else:\n",
        "        original_data.loc[i, 'HighOrLow'] = ''"
      ],
      "metadata": {
        "id": "OpsoBYcZQ9OK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.4 根据收盘价高低和成交量计算 OBV 列\n",
        "\n",
        "row_count = len(original_data)\n",
        "\n",
        "# 添加 OBV 列并初始化为 0\n",
        "original_data['OBV'] = 0\n",
        "\n",
        "# 从倒数第二行开始向上遍历，计算 OBV 列的值\n",
        "for i in range(len(original_data) - 2, -1, -1):\n",
        "    if original_data.loc[i, 'Close_Change'] == 'Down':\n",
        "        original_data.loc[i, 'OBV'] = original_data.loc[i + 1, 'OBV'] - original_data.loc[i, 'Volume']\n",
        "    elif original_data.loc[i, 'Close_Change'] == 'Up':\n",
        "        original_data.loc[i, 'OBV'] = original_data.loc[i + 1, 'OBV'] + original_data.loc[i, 'Volume']\n",
        "\n",
        "# 将 OBV 列移动到 Close 列之后，Volume 列之前\n",
        "obv_column = original_data.pop('OBV')\n",
        "original_data.insert(original_data.columns.get_loc('Volume'), 'OBV', obv_column)"
      ],
      "metadata": {
        "id": "FRYBY_yJBxvp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.5 寻找背离的数据点\n",
        "\n",
        "#初始化新列\n",
        "original_data['Index'] = 0\n",
        "original_data['Found_Row'] = pd.NA\n",
        "original_data['Found_Date'] = pd.NaT\n",
        "original_data['Found_Close'] = pd.NA\n",
        "original_data['Found_OBV'] = pd.NA\n",
        "\n",
        "# 遍历 original_data 中的每一行\n",
        "for i in range(len(original_data)):\n",
        "    if original_data.loc[i, 'HighOrLow'] == 'High':\n",
        "        for j in range(i + 1, len(original_data)):\n",
        "            if original_data.loc[j, 'HighOrLow'] == 'High':\n",
        "                # 返回找到行的信息\n",
        "                original_data.loc[i, 'Found_Row'] = j\n",
        "                original_data.loc[i, 'Found_Date'] = original_data.loc[j, 'Date']\n",
        "                original_data.loc[i, 'Found_Close'] = original_data.loc[j, 'Close']\n",
        "                original_data.loc[i, 'Found_OBV'] = original_data.loc[j, 'OBV']\n",
        "                # 判断 Index 值\n",
        "                if original_data.loc[i, 'Close'] > original_data.loc[j, 'Close'] and original_data.loc[i, 'OBV'] < original_data.loc[j, 'OBV']:\n",
        "                    original_data.loc[i, 'Index'] = 1\n",
        "                elif original_data.loc[i, 'Close'] < original_data.loc[j, 'Close'] and original_data.loc[i, 'OBV'] > original_data.loc[j, 'OBV']:\n",
        "                    original_data.loc[i, 'Index'] = 2\n",
        "                break\n",
        "    elif original_data.loc[i, 'HighOrLow'] == 'Low':\n",
        "        for j in range(i + 1, len(original_data)):\n",
        "            if original_data.loc[j, 'HighOrLow'] == 'Low':\n",
        "                # 返回找到行的信息\n",
        "                original_data.loc[i, 'Found_Row'] = j\n",
        "                original_data.loc[i, 'Found_Date'] = original_data.loc[j, 'Date']\n",
        "                original_data.loc[i, 'Found_Close'] = original_data.loc[j, 'Close']\n",
        "                original_data.loc[i, 'Found_OBV'] = original_data.loc[j, 'OBV']\n",
        "                # 判断 Index 值\n",
        "                if original_data.loc[i, 'Close'] < original_data.loc[j, 'Close'] and original_data.loc[i, 'OBV'] > original_data.loc[j, 'OBV']:\n",
        "                    original_data.loc[i, 'Index'] = 3\n",
        "                elif original_data.loc[i, 'Close'] > original_data.loc[j, 'Close'] and original_data.loc[i, 'OBV'] < original_data.loc[j, 'OBV']:\n",
        "                    original_data.loc[i, 'Index'] = 4\n",
        "                break\n"
      ],
      "metadata": {
        "id": "45c6B5Qzyytf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 【4】创建Google Sheets文件\n",
        "\n",
        "file_name = f\"{stock_code}\"\n",
        "\n",
        "# 检查Google Drive中是否存在同名文件\n",
        "try:\n",
        "    spreadsheet = gc.open(file_name)\n",
        "    print(f\"Spreadsheet '{file_name}' already exists.\")\n",
        "except gspread.exceptions.SpreadsheetNotFound:\n",
        "    print(f\"Creating new file '{file_name}'.\")\n",
        "    spreadsheet = gc.create(file_name)\n",
        "    worksheet = spreadsheet.add_worksheet(title=\"Parameter\", rows=\"100\", cols=\"20\")\n",
        "\n",
        "    # 删除默认的 Sheet1\n",
        "    if 'Sheet1' in [ws.title for ws in spreadsheet.worksheets()]:\n",
        "        spreadsheet.del_worksheet(spreadsheet.worksheet('Sheet1'))"
      ],
      "metadata": {
        "id": "KyhDll4MZBhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa2f1b6-a69c-4ca4-df7a-3b36d5b3906f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spreadsheet 'AAPL' already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2 处理参数工作表\n",
        "\n",
        "try:\n",
        "    # 打开并检查 \"Parameter\" 表中的日期\n",
        "    worksheet = spreadsheet.worksheet(\"Parameter\")\n",
        "    existing_date = worksheet.acell('B1').value\n",
        "    print(f\"Existing file '{file_name}' has a 'Parameter' sheet with Date: {existing_date}\")\n",
        "\n",
        "    overwrite = input(f\"Do you want to overwrite the existing 'Parameter' sheet? (yes/no): \").strip().lower()\n",
        "    if overwrite != 'yes':\n",
        "        print(\"Operation aborted by the user.\")\n",
        "        exit()\n",
        "    else:\n",
        "        print(f\"Overwriting existing 'Parameter' sheet in '{file_name}'.\")\n",
        "        worksheet.clear()  # 清空现有的表内容\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    print(\"Worksheet 'Parameter' not found, creating new 'Parameter' sheet.\")\n",
        "    worksheet = spreadsheet.add_worksheet(title=\"Parameter\", rows=\"100\", cols=\"20\")\n",
        "\n",
        "# 在工作表中写入参数\n",
        "worksheet.update_acell('A1', \"Last Create Date\")\n",
        "worksheet.update_acell('B1', today_date)\n",
        "worksheet.update_acell('A2', \"Stock Code\")\n",
        "worksheet.update_acell('B2', stock_code)\n",
        "worksheet.update_acell('A3', \"API Key\")\n",
        "worksheet.update_acell('B3', api_key)"
      ],
      "metadata": {
        "id": "4rrHdCJIZn2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3 处理历史背离数据工作表\n",
        "\n",
        "styled_data_sheet_name = \"历史背离数据\"\n",
        "try:\n",
        "    styled_data_sheet = spreadsheet.worksheet(styled_data_sheet_name)\n",
        "    styled_data_sheet.clear()  # 清空现有的工作表内容\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    styled_data_sheet = spreadsheet.add_worksheet(title=styled_data_sheet_name, rows=\"1000\", cols=\"20\")\n",
        "\n",
        "# 过滤数据\n",
        "filtered_data = original_data[original_data['HighOrLow'] != '']\n",
        "filtered_data = filtered_data[filtered_data['Index'].isin([1, 2, 3])]\n",
        "\n",
        "# 选择需要显示的列\n",
        "selected_columns = [\"Found_Date\", \"Found_Close\", \"Found_OBV\", \"Date\", \"Close\", \"OBV\", \"Index\"]\n",
        "filtered_data = filtered_data[selected_columns]\n",
        "\n",
        "# 确保 'Date' 和 'Found_date' 列的类型是 datetime，如果不是需要先转换\n",
        "filtered_data[['Date', 'Found_Date']] = filtered_data[['Date', 'Found_Date']].apply(pd.to_datetime)\n",
        "\n",
        "# 将 'Date' 和 'Found_date' 列转换为仅包含日期的格式并转换为字符串\n",
        "filtered_data[['Date', 'Found_Date']] = filtered_data[['Date', 'Found_Date']].apply(lambda x: x.dt.strftime('%Y-%m-%d'))\n",
        "\n",
        "# 将 'Close' 和 'Found_Close' 列转换为数值类型\n",
        "filtered_data['Close'] = pd.to_numeric(filtered_data['Close'], errors='coerce')\n",
        "filtered_data['Found_Close'] = pd.to_numeric(filtered_data['Found_Close'], errors='coerce')\n",
        "\n",
        "# 将 'Close' 和 'Found_Close' 列格式化为小数点后两位并转换为字符串\n",
        "filtered_data['Close'] = filtered_data['Close'].map('{:.2f}'.format)\n",
        "filtered_data['Found_Close'] = filtered_data['Found_Close'].map('{:.2f}'.format)\n",
        "\n",
        "# 确保 'OBV' 和 'Found_OBV' 列转换为数值类型\n",
        "filtered_data['OBV'] = pd.to_numeric(filtered_data['OBV'], errors='coerce')\n",
        "filtered_data['Found_OBV'] = pd.to_numeric(filtered_data['Found_OBV'], errors='coerce')\n",
        "\n",
        "# 缩小 'OBV' 和 'Found_OBV' 列的值，并取整\n",
        "scale_factor = 1e7  # 设置缩放因子\n",
        "filtered_data['OBV'] = (filtered_data['OBV'] / scale_factor).round().astype(int)\n",
        "filtered_data['Found_OBV'] = (filtered_data['Found_OBV'] / scale_factor).round().astype(int)\n",
        "\n",
        "# 将 DataFrame 转换为列表格式\n",
        "data_to_write = [filtered_data.columns.values.tolist()] + filtered_data.values.tolist()\n",
        "\n",
        "# 将数据插入 Google Sheets\n",
        "styled_data_sheet.update(data_to_write)\n",
        "\n",
        "# 使用 gspread-formatting 设置高亮颜色\n",
        "from gspread_formatting import CellFormat, Color, format_cell_range\n",
        "\n",
        "# 定义颜色\n",
        "def get_color(index):\n",
        "    if index == 3:\n",
        "        return Color(0.56, 0.93, 0.56)  # lightgreen\n",
        "    elif index == 2:\n",
        "        return Color(1.0, 0.65, 0.0)    # orange\n",
        "    elif index == 1:\n",
        "        return Color(1.0, 0.63, 0.48)  # lightcoral\n",
        "    return Color(1, 1, 1)  # default to white\n",
        "\n",
        "# 获取所有行数\n",
        "rows = len(filtered_data)\n",
        "\n",
        "# 创建格式化请求\n",
        "for i in range(1, rows + 1):\n",
        "    color = get_color(filtered_data['Index'].iloc[i - 1])\n",
        "    cell_format = CellFormat(backgroundColor=color)\n",
        "    format_cell_range(styled_data_sheet, f\"A{i+1}:G{i+1}\", cell_format)\n",
        "\n",
        "print(f\"Styled data successfully added to the Google Sheets with sheet name '{styled_data_sheet_name}'.\")"
      ],
      "metadata": {
        "id": "BhUQWA17HZU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#【4】另存为 filtered_data，去除不需要的行和列，添加高亮，更容易阅读分析\n",
        "# 和上面输到 Google sheet 的内容一样\n",
        "\n",
        "# 只保留 \"HighOrLow\" 列不为空字符串的行\n",
        "filtered_data = original_data[original_data['HighOrLow']!= '']\n",
        "filtered_data = filtered_data[filtered_data['Index'].isin([1, 2, 3])]\n",
        "\n",
        "# # 选择需要显示的列\n",
        "selected_columns = [ \"Found_Date\", \"Found_Close\", \"Found_OBV\" ,\"Date\",\"Close\", \"OBV\", \"Index\" ]\n",
        "\n",
        "# # 过滤 DataFrame 以只包含选定的列\n",
        "filtered_data = filtered_data[selected_columns]\n",
        "\n",
        "\n",
        "# 确保 'Date' 和 'Found_date' 列的类型是 datetime，如果不是需要先转换\n",
        "filtered_data[['Date', 'Found_Date']] = filtered_data[['Date', 'Found_Date']].apply(pd.to_datetime)\n",
        "# 将 'Date' 和 'Found_date' 列转换为仅包含日期的格式\n",
        "filtered_data[['Date', 'Found_Date']] = filtered_data[['Date', 'Found_Date']].apply(lambda x: x.dt.date)\n",
        "# 将 'Close' 和 'Found_Close' 列转换为数值类型\n",
        "filtered_data['Close'] = pd.to_numeric(filtered_data['Close'], errors='coerce')\n",
        "filtered_data['Found_Close'] = pd.to_numeric(filtered_data['Found_Close'], errors='coerce')\n",
        "# 将 'Close' 和 'Found_Close' 列格式化为小数点后两位并转换为字符串\n",
        "filtered_data['Close'] = filtered_data['Close'].map('{:.2f}'.format)\n",
        "filtered_data['Found_Close'] = filtered_data['Found_Close'].map('{:.2f}'.format)\n",
        "# 确保 'OBV' 和 'Found_OBV' 列转换为数值类型\n",
        "filtered_data['OBV'] = pd.to_numeric(filtered_data['OBV'], errors='coerce')\n",
        "filtered_data['Found_OBV'] = pd.to_numeric(filtered_data['Found_OBV'], errors='coerce')\n",
        "# 缩小 'OBV' 和 'Found_OBV' 列的值，并取整\n",
        "filtered_data['OBV'] = (filtered_data['OBV'] / scale_factor).round().astype(int)\n",
        "filtered_data['Found_OBV'] = (filtered_data['Found_OBV'] / scale_factor).round().astype(int)\n",
        "\n",
        "filtered_data = filtered_data.head(10)\n",
        "\n",
        "# 高亮显示数据\n",
        "def highlight_rows(row):\n",
        "    color = ''\n",
        "    if row['Index'] == 3:\n",
        "        color = 'background-color: lightgreen'\n",
        "    elif row['Index'] == 2:\n",
        "        color = 'background-color: orange'\n",
        "    elif row['Index'] == 1:\n",
        "        color = 'background-color: lightcoral'\n",
        "    return [color] * len(row)\n",
        "\n",
        "# 应用高亮函数\n",
        "styled_data = filtered_data.style.apply(highlight_rows, axis=1)\n",
        "\n",
        "# 显示高亮后的数据\n",
        "display(styled_data)"
      ],
      "metadata": {
        "id": "wcLonp_O_0xG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "e9b4b72f-a9f1-4171-81fd-999964a2df4d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x79e31ab4f9d0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_c8fa6_row0_col0, #T_c8fa6_row0_col1, #T_c8fa6_row0_col2, #T_c8fa6_row0_col3, #T_c8fa6_row0_col4, #T_c8fa6_row0_col5, #T_c8fa6_row0_col6, #T_c8fa6_row4_col0, #T_c8fa6_row4_col1, #T_c8fa6_row4_col2, #T_c8fa6_row4_col3, #T_c8fa6_row4_col4, #T_c8fa6_row4_col5, #T_c8fa6_row4_col6, #T_c8fa6_row9_col0, #T_c8fa6_row9_col1, #T_c8fa6_row9_col2, #T_c8fa6_row9_col3, #T_c8fa6_row9_col4, #T_c8fa6_row9_col5, #T_c8fa6_row9_col6 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "#T_c8fa6_row1_col0, #T_c8fa6_row1_col1, #T_c8fa6_row1_col2, #T_c8fa6_row1_col3, #T_c8fa6_row1_col4, #T_c8fa6_row1_col5, #T_c8fa6_row1_col6, #T_c8fa6_row5_col0, #T_c8fa6_row5_col1, #T_c8fa6_row5_col2, #T_c8fa6_row5_col3, #T_c8fa6_row5_col4, #T_c8fa6_row5_col5, #T_c8fa6_row5_col6, #T_c8fa6_row7_col0, #T_c8fa6_row7_col1, #T_c8fa6_row7_col2, #T_c8fa6_row7_col3, #T_c8fa6_row7_col4, #T_c8fa6_row7_col5, #T_c8fa6_row7_col6 {\n",
              "  background-color: lightcoral;\n",
              "}\n",
              "#T_c8fa6_row2_col0, #T_c8fa6_row2_col1, #T_c8fa6_row2_col2, #T_c8fa6_row2_col3, #T_c8fa6_row2_col4, #T_c8fa6_row2_col5, #T_c8fa6_row2_col6, #T_c8fa6_row3_col0, #T_c8fa6_row3_col1, #T_c8fa6_row3_col2, #T_c8fa6_row3_col3, #T_c8fa6_row3_col4, #T_c8fa6_row3_col5, #T_c8fa6_row3_col6, #T_c8fa6_row6_col0, #T_c8fa6_row6_col1, #T_c8fa6_row6_col2, #T_c8fa6_row6_col3, #T_c8fa6_row6_col4, #T_c8fa6_row6_col5, #T_c8fa6_row6_col6, #T_c8fa6_row8_col0, #T_c8fa6_row8_col1, #T_c8fa6_row8_col2, #T_c8fa6_row8_col3, #T_c8fa6_row8_col4, #T_c8fa6_row8_col5, #T_c8fa6_row8_col6 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_c8fa6\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_c8fa6_level0_col0\" class=\"col_heading level0 col0\" >Found_Date</th>\n",
              "      <th id=\"T_c8fa6_level0_col1\" class=\"col_heading level0 col1\" >Found_Close</th>\n",
              "      <th id=\"T_c8fa6_level0_col2\" class=\"col_heading level0 col2\" >Found_OBV</th>\n",
              "      <th id=\"T_c8fa6_level0_col3\" class=\"col_heading level0 col3\" >Date</th>\n",
              "      <th id=\"T_c8fa6_level0_col4\" class=\"col_heading level0 col4\" >Close</th>\n",
              "      <th id=\"T_c8fa6_level0_col5\" class=\"col_heading level0 col5\" >OBV</th>\n",
              "      <th id=\"T_c8fa6_level0_col6\" class=\"col_heading level0 col6\" >Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_c8fa6_level0_row0\" class=\"row_heading level0 row0\" >8</th>\n",
              "      <td id=\"T_c8fa6_row0_col0\" class=\"data row0 col0\" >2024-04-05</td>\n",
              "      <td id=\"T_c8fa6_row0_col1\" class=\"data row0 col1\" >169.58</td>\n",
              "      <td id=\"T_c8fa6_row0_col2\" class=\"data row0 col2\" >1620</td>\n",
              "      <td id=\"T_c8fa6_row0_col3\" class=\"data row0 col3\" >2024-04-19</td>\n",
              "      <td id=\"T_c8fa6_row0_col4\" class=\"data row0 col4\" >165.00</td>\n",
              "      <td id=\"T_c8fa6_row0_col5\" class=\"data row0 col5\" >1621</td>\n",
              "      <td id=\"T_c8fa6_row0_col6\" class=\"data row0 col6\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8fa6_level0_row1\" class=\"row_heading level0 row1\" >9</th>\n",
              "      <td id=\"T_c8fa6_row1_col0\" class=\"data row1 col0\" >2024-03-15</td>\n",
              "      <td id=\"T_c8fa6_row1_col1\" class=\"data row1 col1\" >172.62</td>\n",
              "      <td id=\"T_c8fa6_row1_col2\" class=\"data row1 col2\" >1703</td>\n",
              "      <td id=\"T_c8fa6_row1_col3\" class=\"data row1 col3\" >2024-04-12</td>\n",
              "      <td id=\"T_c8fa6_row1_col4\" class=\"data row1 col4\" >176.55</td>\n",
              "      <td id=\"T_c8fa6_row1_col5\" class=\"data row1 col5\" >1652</td>\n",
              "      <td id=\"T_c8fa6_row1_col6\" class=\"data row1 col6\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8fa6_level0_row2\" class=\"row_heading level0 row2\" >20</th>\n",
              "      <td id=\"T_c8fa6_row2_col0\" class=\"data row2 col0\" >2023-12-15</td>\n",
              "      <td id=\"T_c8fa6_row2_col1\" class=\"data row2 col1\" >197.57</td>\n",
              "      <td id=\"T_c8fa6_row2_col2\" class=\"data row2 col2\" >1747</td>\n",
              "      <td id=\"T_c8fa6_row2_col3\" class=\"data row2 col3\" >2024-01-26</td>\n",
              "      <td id=\"T_c8fa6_row2_col4\" class=\"data row2 col4\" >192.42</td>\n",
              "      <td id=\"T_c8fa6_row2_col5\" class=\"data row2 col5\" >1756</td>\n",
              "      <td id=\"T_c8fa6_row2_col6\" class=\"data row2 col6\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8fa6_level0_row3\" class=\"row_heading level0 row3\" >67</th>\n",
              "      <td id=\"T_c8fa6_row3_col0\" class=\"data row3 col0\" >2023-02-17</td>\n",
              "      <td id=\"T_c8fa6_row3_col1\" class=\"data row3 col1\" >152.55</td>\n",
              "      <td id=\"T_c8fa6_row3_col2\" class=\"data row3 col2\" >1381</td>\n",
              "      <td id=\"T_c8fa6_row3_col3\" class=\"data row3 col3\" >2023-03-03</td>\n",
              "      <td id=\"T_c8fa6_row3_col4\" class=\"data row3 col4\" >151.03</td>\n",
              "      <td id=\"T_c8fa6_row3_col5\" class=\"data row3 col5\" >1387</td>\n",
              "      <td id=\"T_c8fa6_row3_col6\" class=\"data row3 col6\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8fa6_level0_row4\" class=\"row_heading level0 row4\" >68</th>\n",
              "      <td id=\"T_c8fa6_row4_col0\" class=\"data row4 col0\" >2023-02-10</td>\n",
              "      <td id=\"T_c8fa6_row4_col1\" class=\"data row4 col1\" >151.01</td>\n",
              "      <td id=\"T_c8fa6_row4_col2\" class=\"data row4 col2\" >1349</td>\n",
              "      <td id=\"T_c8fa6_row4_col3\" class=\"data row4 col3\" >2023-02-24</td>\n",
              "      <td id=\"T_c8fa6_row4_col4\" class=\"data row4 col4\" >146.71</td>\n",
              "      <td id=\"T_c8fa6_row4_col5\" class=\"data row4 col5\" >1360</td>\n",
              "      <td id=\"T_c8fa6_row4_col6\" class=\"data row4 col6\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8fa6_level0_row5\" class=\"row_heading level0 row5\" >71</th>\n",
              "      <td id=\"T_c8fa6_row5_col0\" class=\"data row5 col0\" >2022-11-18</td>\n",
              "      <td id=\"T_c8fa6_row5_col1\" class=\"data row5 col1\" >151.29</td>\n",
              "      <td id=\"T_c8fa6_row5_col2\" class=\"data row5 col2\" >1491</td>\n",
              "      <td id=\"T_c8fa6_row5_col3\" class=\"data row5 col3\" >2023-02-03</td>\n",
              "      <td id=\"T_c8fa6_row5_col4\" class=\"data row5 col4\" >154.50</td>\n",
              "      <td id=\"T_c8fa6_row5_col5\" class=\"data row5 col5\" >1382</td>\n",
              "      <td id=\"T_c8fa6_row5_col6\" class=\"data row5 col6\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8fa6_level0_row6\" class=\"row_heading level0 row6\" >82</th>\n",
              "      <td id=\"T_c8fa6_row6_col0\" class=\"data row6 col0\" >2022-10-28</td>\n",
              "      <td id=\"T_c8fa6_row6_col1\" class=\"data row6 col1\" >155.74</td>\n",
              "      <td id=\"T_c8fa6_row6_col2\" class=\"data row6 col2\" >1458</td>\n",
              "      <td id=\"T_c8fa6_row6_col3\" class=\"data row6 col3\" >2022-11-18</td>\n",
              "      <td id=\"T_c8fa6_row6_col4\" class=\"data row6 col4\" >151.29</td>\n",
              "      <td id=\"T_c8fa6_row6_col5\" class=\"data row6 col5\" >1491</td>\n",
              "      <td id=\"T_c8fa6_row6_col6\" class=\"data row6 col6\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8fa6_level0_row7\" class=\"row_heading level0 row7\" >116</th>\n",
              "      <td id=\"T_c8fa6_row7_col0\" class=\"data row7 col0\" >2022-02-04</td>\n",
              "      <td id=\"T_c8fa6_row7_col1\" class=\"data row7 col1\" >172.39</td>\n",
              "      <td id=\"T_c8fa6_row7_col2\" class=\"data row7 col2\" >1982</td>\n",
              "      <td id=\"T_c8fa6_row7_col3\" class=\"data row7 col3\" >2022-03-25</td>\n",
              "      <td id=\"T_c8fa6_row7_col4\" class=\"data row7 col4\" >174.72</td>\n",
              "      <td id=\"T_c8fa6_row7_col5\" class=\"data row7 col5\" >1863</td>\n",
              "      <td id=\"T_c8fa6_row7_col6\" class=\"data row7 col6\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8fa6_level0_row8\" class=\"row_heading level0 row8\" >123</th>\n",
              "      <td id=\"T_c8fa6_row8_col0\" class=\"data row8 col0\" >2022-01-14</td>\n",
              "      <td id=\"T_c8fa6_row8_col1\" class=\"data row8 col1\" >173.07</td>\n",
              "      <td id=\"T_c8fa6_row8_col2\" class=\"data row8 col2\" >1907</td>\n",
              "      <td id=\"T_c8fa6_row8_col3\" class=\"data row8 col3\" >2022-02-04</td>\n",
              "      <td id=\"T_c8fa6_row8_col4\" class=\"data row8 col4\" >172.39</td>\n",
              "      <td id=\"T_c8fa6_row8_col5\" class=\"data row8 col5\" >1982</td>\n",
              "      <td id=\"T_c8fa6_row8_col6\" class=\"data row8 col6\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8fa6_level0_row9\" class=\"row_heading level0 row9\" >125</th>\n",
              "      <td id=\"T_c8fa6_row9_col0\" class=\"data row9 col0\" >2022-01-07</td>\n",
              "      <td id=\"T_c8fa6_row9_col1\" class=\"data row9 col1\" >172.17</td>\n",
              "      <td id=\"T_c8fa6_row9_col2\" class=\"data row9 col2\" >1865</td>\n",
              "      <td id=\"T_c8fa6_row9_col3\" class=\"data row9 col3\" >2022-01-21</td>\n",
              "      <td id=\"T_c8fa6_row9_col4\" class=\"data row9 col4\" >162.41</td>\n",
              "      <td id=\"T_c8fa6_row9_col5\" class=\"data row9 col5\" >1868</td>\n",
              "      <td id=\"T_c8fa6_row9_col6\" class=\"data row9 col6\" >3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}