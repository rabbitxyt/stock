{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitxyt/stock/blob/main/multiple_stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 【1】安装库和检测环境\n",
        "\n",
        "try:\n",
        "    import google.auth\n",
        "    import gspread\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import pickle\n",
        "    import requests\n",
        "    import openpyxl\n",
        "    import pytz\n",
        "    from datetime import datetime, timedelta\n",
        "    from googleapiclient.discovery import build\n",
        "except ImportError:\n",
        "    !pip install google-auth gspread gspread-formatting google-api-python-client pandas requests openpyxl pytz"
      ],
      "metadata": {
        "id": "Nu_l34V5JabN"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 检测是否在Google Colab环境中运行\n",
        "try:\n",
        "    from google.colab import drive, auth  # 用于在Google Colab中挂载Google Drive和进行用户认证\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    # 在Google Colab中运行的设置\n",
        "    drive.mount('/content/drive') # 挂载Google Drive\n",
        "    auth.authenticate_user() # 认证和授权\n",
        "    from google.auth import default\n",
        "    creds, _ = default()\n",
        "else:\n",
        "    # 在本地运行的设置，使用服务账号凭证文件\n",
        "    from google.oauth2.service_account import Credentials\n",
        "    creds = Credentials.from_service_account_file('path/to/your/service_account.json')  # 请替换为你的服务账号文件路径\n",
        "\n",
        "# 使用凭证登录\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQK0wC8OJcAZ",
        "outputId": "78a0c313-00b0-4555-ec07-b8df79e07f9a"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 股票代码列表\n",
        "# stock_codes = [\"AAPL\", \"MSFT\", \"GOOGL\"]  # 可以根据需要添加更多股票代码\n",
        "# 从TXT文件读取股票代码列表\n",
        "def read_stock_codes_from_txt(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        stock_codes = file.read().splitlines()\n",
        "    return stock_codes\n",
        "\n",
        "# 读取股票代码\n",
        "txt_file_path = '/content/drive/My Drive/stock_codes.txt'\n",
        "stock_codes = read_stock_codes_from_txt(txt_file_path)\n",
        "\n",
        "# 获取股票数据的函数\n",
        "def get_stock_data(stock_code, api_key):\n",
        "    base_url = \"https://www.alphavantage.co/query\"\n",
        "    params = {\n",
        "        \"function\": \"TIME_SERIES_WEEKLY\",\n",
        "        \"symbol\": stock_code,\n",
        "        \"apikey\": api_key\n",
        "    }\n",
        "    response = requests.get(base_url, params=params)\n",
        "    data = response.json()\n",
        "    return data\n",
        "\n",
        "# 设置 API Key\n",
        "api_key = \"VAVS6TS3HVTPGWQ9\"\n",
        "\n",
        "# 获取并保存每个股票的数据\n",
        "stock_data_dict = {}\n",
        "for stock_code in stock_codes:\n",
        "    stock_data = get_stock_data(stock_code, api_key)\n",
        "    stock_data_dict[stock_code] = stock_data\n",
        "\n",
        "# 保存到本地文件\n",
        "import pickle\n",
        "with open('/content/drive/My Drive/stock_data_dict.pkl', 'wb') as f:\n",
        "    pickle.dump(stock_data_dict, f)"
      ],
      "metadata": {
        "id": "UAMS8yINJdzh"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 从本地文件加载股票数据 5s\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "\n",
        "with open('/content/drive/My Drive/stock_data_dict.pkl', 'rb') as f:\n",
        "    stock_data_dict = pickle.load(f)\n",
        "\n",
        "# 检查Google Drive中是否已经存在名为\"Stock\"的文件\n",
        "try:\n",
        "    spreadsheet = gc.open(\"Stock\")\n",
        "    print(\"Existing 'Stock' spreadsheet found and will be overwritten.\")\n",
        "    # 删除默认的 Sheet1\n",
        "    worksheet = spreadsheet.sheet1\n",
        "    spreadsheet.del_worksheet(worksheet)\n",
        "except gspread.exceptions.SpreadsheetNotFound:\n",
        "    spreadsheet = gc.create(\"Stock\")\n",
        "    print(\"Creating new 'Stock' spreadsheet.\")\n",
        "\n",
        "\n",
        "# 定义数据处理和存储的函数\n",
        "def process_and_store_stock_data(stock_code, data, spreadsheet):\n",
        "    # 准备 DataFrame 数据\n",
        "    time_series = data.get(\"Weekly Time Series\", {})\n",
        "    original_data = {\n",
        "        \"Date\": [],\n",
        "        \"Close\": [],\n",
        "        \"Volume\": []\n",
        "    }\n",
        "\n",
        "    for date, metrics in time_series.items():\n",
        "        original_data[\"Date\"].append(date)\n",
        "        original_data[\"Close\"].append(float(metrics[\"4. close\"]))\n",
        "        original_data[\"Volume\"].append(int(metrics[\"5. volume\"]))\n",
        "\n",
        "    original_data = pd.DataFrame(original_data)\n",
        "\n",
        "    # Check if the DataFrame is empty before proceeding\n",
        "    if original_data.empty:\n",
        "        print(f\"No data found for {stock_code}. Skipping...\")\n",
        "        return\n",
        "\n",
        "    original_data['Date'] = pd.to_datetime(original_data['Date'])\n",
        "    original_data['Volume'] = pd.to_numeric(original_data['Volume'], errors='coerce')\n",
        "\n",
        "    # 获取当前时间并指定时区，例如使用美国东部时间（ET）\n",
        "    now = datetime.now(pytz.timezone('US/Eastern'))\n",
        "\n",
        "    # 判断今天是星期几\n",
        "    weekday = now.weekday()\n",
        "\n",
        "    # 判断是否已经过了周五的市场收盘时间（下午5点）\n",
        "    friday_close_time = now.replace(hour=17, minute=0, second=0, microsecond=0)\n",
        "\n",
        "    # 如果今天是周六(5)或周日(6)或者是周五且已经过了收盘时间\n",
        "    if weekday > 5 or (weekday == 5 and now > friday_close_time):\n",
        "        # 获取本周日的日期\n",
        "        end_date = now + timedelta(days=(6 - weekday))\n",
        "    else:\n",
        "        # 获取上周日的日期\n",
        "        end_date = now - timedelta(days=(weekday + 1))\n",
        "\n",
        "    # 将 end_date 转换为不含时区信息的 datetime 对象\n",
        "    end_date = end_date.replace(tzinfo=None)\n",
        "\n",
        "    # 过滤只保留一周收盘后的数据\n",
        "    original_data = original_data[original_data['Date'] <= end_date].reset_index(drop=True)\n",
        "\n",
        "    # 添加 Close_Change 列\n",
        "    original_data['Close_Change'] = 'NA'\n",
        "    for i in range(len(original_data) - 1):\n",
        "        if original_data.loc[i, 'Close'] > original_data.loc[i + 1, 'Close']:\n",
        "            original_data.loc[i, 'Close_Change'] = 'Up'\n",
        "        elif original_data.loc[i, 'Close'] < original_data.loc[i + 1, 'Close']:\n",
        "            original_data.loc[i, 'Close_Change'] = 'Down'\n",
        "\n",
        "    # 添加 HighOrLow 列\n",
        "    original_data['HighOrLow'] = 'NA'\n",
        "    if original_data.loc[0, 'Close_Change'] == 'Up':\n",
        "        original_data.loc[0, 'HighOrLow'] = 'High'\n",
        "    elif original_data.loc[0, 'Close_Change'] == 'Down':\n",
        "        original_data.loc[0, 'HighOrLow'] = 'Low'\n",
        "\n",
        "    for i in range(1, len(original_data) - 1):\n",
        "        current_close = original_data.loc[i, 'Close']\n",
        "        previous_close = original_data.loc[i - 1, 'Close']\n",
        "        next_close = original_data.loc[i + 1, 'Close']\n",
        "        if current_close > previous_close and current_close > next_close:\n",
        "            original_data.loc[i, 'HighOrLow'] = 'High'\n",
        "        elif current_close < previous_close and current_close < next_close:\n",
        "            original_data.loc[i, 'HighOrLow'] = 'Low'\n",
        "        else:\n",
        "            original_data.loc[i, 'HighOrLow'] = ''\n",
        "\n",
        "    # 添加 OBV 列\n",
        "    original_data['OBV'] = 0\n",
        "    for i in range(len(original_data) - 2, -1, -1):\n",
        "        if original_data.loc[i, 'Close_Change'] == 'Down':\n",
        "            original_data.loc[i, 'OBV'] = original_data.loc[i + 1, 'OBV'] - original_data.loc[i, 'Volume']\n",
        "        elif original_data.loc[i, 'Close_Change'] == 'Up':\n",
        "            original_data.loc[i, 'OBV'] = original_data.loc[i + 1, 'OBV'] + original_data.loc[i, 'Volume']\n",
        "    obv_column = original_data.pop('OBV')\n",
        "    original_data.insert(original_data.columns.get_loc('Volume'), 'OBV', obv_column)\n",
        "\n",
        "    # 初始化新列\n",
        "    original_data['Index'] = 0\n",
        "    original_data['Found_Row'] = pd.NA\n",
        "    original_data['Found_Date'] = pd.NaT\n",
        "    original_data['Found_Close'] = np.nan\n",
        "    original_data['Found_OBV'] = np.nan\n",
        "\n",
        "    # 寻找背离的数据点\n",
        "    for i in range(len(original_data)):\n",
        "        if original_data.loc[i, 'HighOrLow'] == 'High':\n",
        "            for j in range(i + 1, len(original_data)):\n",
        "                if original_data.loc[j, 'HighOrLow'] == 'High':\n",
        "                    original_data.loc[i, 'Found_Row'] = j\n",
        "                    original_data.loc[i, 'Found_Date'] = original_data.loc[j, 'Date']\n",
        "                    original_data.loc[i, 'Found_Close'] = float(original_data.loc[j, 'Close'])\n",
        "                    original_data.loc[i, 'Found_OBV'] = int(original_data.loc[j, 'OBV'])\n",
        "                    if original_data.loc[i, 'Close'] > original_data.loc[j, 'Close'] and original_data.loc[i, 'OBV'] < original_data.loc[j, 'OBV']:\n",
        "                        original_data.loc[i, 'Index'] = 1\n",
        "                    elif original_data.loc[i, 'Close'] < original_data.loc[j, 'Close'] and original_data.loc[i, 'OBV'] > original_data.loc[j, 'OBV']:\n",
        "                        original_data.loc[i, 'Index'] = 2\n",
        "                    break\n",
        "        elif original_data.loc[i, 'HighOrLow'] == 'Low':\n",
        "            for j in range(i + 1, len(original_data)):\n",
        "                if original_data.loc[j, 'HighOrLow'] == 'Low':\n",
        "                    original_data.loc[i, 'Found_Row'] = j\n",
        "                    original_data.loc[i, 'Found_Date'] = original_data.loc[j, 'Date']\n",
        "                    original_data.loc[i, 'Found_Close'] = float(original_data.loc[j, 'Close'])\n",
        "                    original_data.loc[i, 'Found_OBV'] = int(original_data.loc[j, 'OBV'])\n",
        "                    if original_data.loc[i, 'Close'] < original_data.loc[j, 'Close'] and original_data.loc[i, 'OBV'] > original_data.loc[j, 'OBV']:\n",
        "                        original_data.loc[i, 'Index'] = 3\n",
        "                    elif original_data.loc[i, 'Close'] > original_data.loc[j, 'Close'] and original_data.loc[i, 'OBV'] < original_data.loc[j, 'OBV']:\n",
        "                        original_data.loc[i, 'Index'] = 4\n",
        "                    break\n",
        "\n",
        "    # 填充 NA 值以便于转换为 int\n",
        "    original_data['Found_OBV'] = original_data['Found_OBV'].fillna(0).astype(int)\n",
        "\n",
        "    # 将 Date 和 Found_Date 列转换为字符串\n",
        "    original_data['Date'] = original_data['Date'].dt.strftime('%Y-%m-%d')\n",
        "    original_data['Found_Date'] = original_data['Found_Date'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    # 将其他 NA 值转换为适合的格式\n",
        "    original_data['Found_Close'] = original_data['Found_Close'].fillna(0).astype(float)\n",
        "    original_data['Found_Row'] = original_data['Found_Row'].fillna(0).astype(int)\n",
        "    original_data['Index'] = original_data['Index'].fillna(0).astype(int)\n",
        "\n",
        "    # 确保所有值在合理范围内\n",
        "    original_data = original_data.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    # 只保留 \"HighOrLow\" 列不为空字符串的行\n",
        "    filtered_data = original_data[original_data['HighOrLow'] != '']\n",
        "    filtered_data = filtered_data[filtered_data['Index'].isin([1, 2, 3])]\n",
        "\n",
        "    # 选择需要显示的列\n",
        "    selected_columns = [\"Found_Date\", \"Found_Close\", \"Found_OBV\", \"Date\", \"Close\", \"OBV\", \"Index\"]\n",
        "    filtered_data = filtered_data[selected_columns]\n",
        "\n",
        "    # 将 'Close' 和 'Found_Close' 列格式化为小数点后两位并转换为字符串\n",
        "    filtered_data['Close'] = filtered_data['Close'].map('{:.2f}'.format)\n",
        "    filtered_data['Found_Close'] = filtered_data['Found_Close'].map('{:.2f}'.format)\n",
        "\n",
        "    # 缩小 'OBV' 和 'Found_OBV' 列的值，并取整\n",
        "    scale_factor = 1e7  # 设置缩放因子\n",
        "    filtered_data['OBV'] = (filtered_data['OBV'] / scale_factor).round().astype(int)\n",
        "    filtered_data['Found_OBV'] = (filtered_data['Found_OBV'] / scale_factor).round().astype(int)\n",
        "\n",
        "    # 创建或清空工作表\n",
        "    try:\n",
        "        worksheet = spreadsheet.worksheet(stock_code)\n",
        "        worksheet.clear()\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        worksheet = spreadsheet.add_worksheet(title=stock_code, rows=\"1000\", cols=\"20\")\n",
        "\n",
        "    # 将 DataFrame 转换为列表格式，并插入 Google Sheets\n",
        "    worksheet.update([filtered_data.columns.values.tolist()] + filtered_data.values.tolist())\n",
        "\n",
        "    print(f\"Data for {stock_code} successfully added to the Google Sheets.\")\n",
        "\n",
        "  # 处理并存储每个股票的数据\n",
        "for stock_code in stock_data_dict:\n",
        "    stock_data = stock_data_dict[stock_code]\n",
        "    process_and_store_stock_data(stock_code, stock_data, spreadsheet)"
      ],
      "metadata": {
        "id": "zsyLxRYSKQl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' # 使用 gspread-formatting 设置高亮颜色 非常慢，三个表跑了1m25s，在Apps Script跑也差不多时间\n",
        "\n",
        "from gspread_formatting import CellFormat, Color, format_cell_range\n",
        "\n",
        "# 定义颜色\n",
        "def get_color(index):\n",
        "    if index == 3:\n",
        "        return Color(0.56, 0.93, 0.56)  # lightgreen\n",
        "    elif index == 2:\n",
        "        return Color(1.0, 0.65, 0.0)    # orange\n",
        "    elif index == 1:\n",
        "        return Color(1.0, 0.63, 0.48)  # lightcoral\n",
        "    return Color(1, 1, 1)  # default to white\n",
        "\n",
        "# 遍历所有的 tab 应用格式化\n",
        "for stock_code in stock_data_dict:\n",
        "    worksheet = spreadsheet.worksheet(stock_code)\n",
        "    filtered_data = original_data[original_data['HighOrLow'] != '']\n",
        "    filtered_data = filtered_data[filtered_data['Index'].isin([1, 2, 3])]\n",
        "\n",
        "    # 获取所有行数\n",
        "    rows = len(filtered_data)\n",
        "\n",
        "    # 创建格式化请求\n",
        "    for i in range(1, rows + 1):\n",
        "        color = get_color(filtered_data['Index'].iloc[i - 1])\n",
        "        cell_format = CellFormat(backgroundColor=color)\n",
        "        try:\n",
        "            format_cell_range(worksheet, f\"A{i+1}:G{i+1}\", cell_format)\n",
        "        except Exception as e:\n",
        "            print(f\"Error formatting range A{i+1}:G{i+1} - {e}\")\n",
        "\n",
        "print(\"Styled data successfully added to the Google Sheets.\") '''"
      ],
      "metadata": {
        "id": "RgZqK0DoZKz9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}